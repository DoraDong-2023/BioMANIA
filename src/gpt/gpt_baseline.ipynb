{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84252b5b-f228-45a1-8335-962270be9d9e",
   "metadata": {},
   "source": [
    "# Setup OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7d9109-7d2e-487e-8b10-2bf3ba99d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e10ab8b-16a2-44ee-be04-5f83231a2eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "361\n",
      "1443\n",
      "1986\n",
      "182 182\n"
     ]
    }
   ],
   "source": [
    "import gpt_interface\n",
    "import random\n",
    "import bz2\n",
    "import json\n",
    "from tqdm import auto as tqdm\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)  # turn off logging\n",
    "mode = 'openai'\n",
    "k_shot = 5\n",
    "secrets = gpt_interface.setup_openai('secrets.json', mode=mode)\n",
    "# load data\n",
    "with bz2.open('API_inquiry_annotate.json.bz2', 'rt') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# load val ids\n",
    "with open(\"API_instruction_testval_query_ids.json\", 'r') as file:\n",
    "    files_ids = json.load(file)\n",
    "\n",
    "test = [dict(query=row['query'], gold=row['api_name']) for row in [i for i in data if i['query_id'] in files_ids['test']]]\n",
    "val = [dict(query=row['query'], gold=row['api_name']) for row in [i for i in data if i['query_id'] in files_ids['val']]]\n",
    "print(len(test))\n",
    "print(len(val))\n",
    "# add K-shot \n",
    "shuffled = [dict(query=row['query'], gold=row['api_name']) for row in [i for i in data if i['query_id'] not in files_ids['val'] and i['query_id'] not in files_ids['test']]]\n",
    "random.Random(0).shuffle(shuffled)\n",
    "print(len(shuffled))\n",
    "print(len(data))\n",
    "assert len(data)==len(test)+len(val)+len(shuffled)\n",
    "train = shuffled[:k_shot]\n",
    "# all-apis\n",
    "import re, os\n",
    "from string import punctuation\n",
    "end_of_docstring_summary = re.compile(r'[{}\\n]+'.format(re.escape(punctuation)))\n",
    "all_apis = {x['api_name']: end_of_docstring_summary.split(x['Docstring'])[0].strip() for x in data}\n",
    "all_apis = list(all_apis.items())\n",
    "all_apis_json = {i[0]:i[1] for i in all_apis}\n",
    "print(len(all_apis), len(all_apis_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ac6a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus...\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "class ToolRetriever:\n",
    "    def __init__(self, corpus_tsv_path = \"\", model_path=\"\",shuffled_data=[]):\n",
    "        self.build_retrieval_corpus(corpus_tsv_path, model_path,shuffled_data)\n",
    "    def build_retrieval_corpus(self, corpus_tsv_path, model_path,shuffled_data):\n",
    "        print(\"Building corpus...\")\n",
    "        self.corpus_tsv_path = corpus_tsv_path\n",
    "        self.model_path = model_path\n",
    "        documents_df = pd.read_csv(self.corpus_tsv_path, sep='\\t')\n",
    "        corpus, self.corpus2tool = process_retrieval_document_query_version(documents_df)\n",
    "        corpus_ids = list(corpus.keys())\n",
    "        corpus = [corpus[cid] for cid in corpus_ids]\n",
    "        self.corpus = corpus\n",
    "        self.embedder = SentenceTransformer(self.model_path, device=device)\n",
    "        self.corpus_embeddings = self.embedder.encode(self.corpus, convert_to_tensor=True)\n",
    "        self.shuffled_data = shuffled_data\n",
    "        self.shuffled_queries = [item['query'] for item in shuffled_data]\n",
    "        self.shuffled_query_embeddings = self.embedder.encode(self.shuffled_queries, convert_to_tensor=True)\n",
    "    def retrieving(self, query, top_k):\n",
    "        query_embedding = self.embedder.encode(query, convert_to_tensor=True)\n",
    "        hits = util.semantic_search(query_embedding, self.corpus_embeddings, top_k=top_k, score_function=util.cos_sim) #170*\n",
    "        retrieved_apis = [self.corpus2tool[self.corpus[hit['corpus_id']]] for hit in hits[0]]\n",
    "        #scores = [hit['score'] for hit in hits[0]]\n",
    "        return retrieved_apis[:top_k]\n",
    "    def retrieve_similar_queries(self, query, shot_k=5):\n",
    "        query_embedding = self.embedder.encode(query, convert_to_tensor=True)\n",
    "        hits = util.semantic_search(query_embedding, self.shuffled_query_embeddings, top_k=shot_k, score_function=util.cos_sim)\n",
    "        #similar_queries = [shuffled_data[hit['corpus_id']] for hit in hits[0]]\n",
    "        similar_queries = [\"\\nInstruction: \" + self.shuffled_data[hit['corpus_id']]['query'] + \"\\nFunction: \" + self.shuffled_data[hit['corpus_id']]['gold'] for hit in hits[0]]\n",
    "        return ''.join(similar_queries)\n",
    "\n",
    "def process_retrieval_document_query_version(documents_df):\n",
    "    ir_corpus = {}\n",
    "    corpus2tool = {}\n",
    "    for row in documents_df.itertuples():\n",
    "        doc = json.loads(row.document_content)\n",
    "        ir_corpus[row.docid] = compress_api_str_from_list_query_version(doc)\n",
    "        corpus2tool[compress_api_str_from_list_query_version(doc)] = doc['api_calling'][0].split('(')[0]\n",
    "    return ir_corpus, corpus2tool\n",
    "\n",
    "def compress_api_str_from_list_query_version(api):\n",
    "    api_name = api['api_calling'][0].split('(')[0]\n",
    "    api_desc_truncated = api['api_description'].split('\\n')[0]\n",
    "    req_params = json.dumps(api['required_parameters'])\n",
    "    opt_params = json.dumps(api['optional_parameters'])\n",
    "    return_schema = json.dumps(api['Returns'])\n",
    "    compressed_str = f\"{api_name}, {api_desc_truncated}, required_params: {req_params}, optional_params: {opt_params}, return_schema: {return_schema}\"\n",
    "    return compressed_str\n",
    "\n",
    "def load_errors(fname):\n",
    "    with open(fname, 'rt') as f:\n",
    "        data = json.load(f)\n",
    "    wrong = [ex for ex in data if not ex['correct']]\n",
    "    random.Random(0).shuffle(wrong)\n",
    "    return wrong\n",
    "\n",
    "#load_errors('5-shot-generate/gpt-4.json')[:5]\n",
    "\n",
    "import pandas as pd\n",
    "device = 'cuda:0'\n",
    "#retriever = ToolRetriever(corpus_tsv_path=\"/Users/doradong/Repo/2023_yanglu_biochatbot/src/data/standard_process/scanpy/retriever_train_data/corpus.tsv\", model_path=\"/Users/doradong/hugging_models/retrievers/\",shuffled_data=shuffled)\n",
    "retriever = ToolRetriever(corpus_tsv_path=\"/home/z6dong/BioChat/refer/src/2023_yanglu_biochatbot/src/data/standard_process/scanpy/retriever_train_data/corpus.tsv\", model_path=\"/home/z6dong/BioChat/hugging_models/retriever_model_finetuned/scanpy/assigned/\",shuffled_data=shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e687de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_index = 'similarseed' # 'similarseed' or randomseed\n",
    "# whether use similar shot example retriving mode, the similar shot example retriving is \n",
    "# to retrieve the similar queries that similar to the input query\n",
    "# noted that this mode always retrieve 5 shot queries for the same API, as the query for same API is always similar\n",
    "oracle_index = 'noncorrected' # 'noncorrected' or corrected\n",
    "# whether use the corrected mode after retrieving API. The retrieved API is different from retrieved query, \n",
    "# retrieved API will provide an API list for gpt to select\n",
    "# if under correct mode, we will put the ground truth API into the retrieved API list, \n",
    "# and delete the last one API under the retrieved API list\n",
    "retrieved_index = 'retrieved' # nonretrieved or retrieved\n",
    "# if using retrieved mode, then we will provide a filtered retrieved list\n",
    "# otherwise, we will provide the whole API list for gpt to select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf93a2-898b-4db0-b036-68d9707207ab",
   "metadata": {},
   "source": [
    "# Query to API selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cea28-ee96-4a90-9985-5c176572c54d",
   "metadata": {},
   "source": [
    "## K-shot\n",
    "\n",
    "Here, GPT does not see candidate list of APIs, it just tries to tell the correct function from memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59abc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Task: name the function from the ScanPy library that should be used for the instruction. Only use function whose names start with scanpy. Do not give arguments.\n",
    "\n",
    "{similar_queries}\n",
    "\n",
    "Instruction: {query}\n",
    "Function: \n",
    "\"\"\"\n",
    "prompt = prompt.strip('\\n')\n",
    "print(prompt)\n",
    "\n",
    "def run_gpt(test, gpt_model, prompt, dout, mode, max_tokens=20,title=\"\"):\n",
    "    correct = []\n",
    "    for ex in (pbar := tqdm.tqdm(test)):\n",
    "        if mode_index == 'similarseed':\n",
    "            similar_queries = retriever.retrieve_similar_queries(ex['query'],shot_k=5)\n",
    "        elif mode_index == 'randomseed':\n",
    "            sampled_shuffled = random.sample(shuffled, 5)\n",
    "            similar_queries = \"\".join([\"\\nInstruction: \" + ex['query'] + \"\\nFunction: \" + ex['gold'] for ex in sampled_shuffled])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        print(prompt.format(query=ex['query'],similar_queries=similar_queries))\n",
    "        p = gpt_interface.query_openai(prompt.format(query=ex['query'],similar_queries=similar_queries), mode=mode, model=gpt_model, max_tokens=max_tokens)\n",
    "        p = p.split(',')[0]  # hack for if GPT answers this or that\n",
    "        p = p.split('(')[0]\n",
    "        p = p.split(' or ')[0]\n",
    "        p = p.strip()\n",
    "        ex['pred'] = p\n",
    "        ex['correct'] = c = ex['pred'] == ex['gold']\n",
    "        correct.append(c)\n",
    "        pbar.set_description('correct: {}'.format(sum(correct)/len(correct)))\n",
    "    with open(os.path.join(dout, '{}.json'.format(title)), 'wt') as f:\n",
    "        json.dump(test, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86df471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_name = \"{}-shot-generate\".format(k_shot)\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gpt(test, 'gpt-3.5-turbo-16k', prompt, '{}-shot-generate'.format(k_shot), mode,title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c071a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.4065934065934066: 100%|█████████████████████████████| 182/182 [04:34<00:00,  1.51s/it]'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_gpt(test, 'gpt-4', prompt, '{}-shot-generate'.format(k_shot), mode,title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'gpt-3.5-turbo-16k-trainsample'\n",
    "run_gpt(val, 'gpt-3.5-turbo-16k', prompt, '{}-shot-generate'.format(k_shot), mode,title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'gpt-4-trainsample'\n",
    "run_gpt(val, 'gpt-4', prompt, '{}-shot-generate'.format(k_shot), mode,title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5bf4c-c263-4ed8-9176-ca553e287a54",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Here, GPT sees the list of available APIs and tries to pick out the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04bb044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Task: choose one of the following functions to use for the instruction.\"\"\"\n",
    "prompt += \"\"\"\\n{retrieved_apis}\"\"\"\n",
    "prompt+=\"\"\"\\n{similar_queries}\"\"\"\n",
    "prompt += \"\"\"\n",
    "Instruction: {query}\n",
    "Function: \n",
    "\"\"\"\n",
    "prompt = prompt.strip('\\n')\n",
    "print(prompt)\n",
    "\n",
    "def run_gpt_new(test, gpt_model, prompt, dout, mode, max_tokens=20,top_k=3,title=\"\"):\n",
    "    correct = []\n",
    "    for ex in (pbar := tqdm.tqdm(test)):\n",
    "        retrieved_api_list = retriever.retrieving(ex['query'], top_k=top_k)\n",
    "        if mode_index == 'similarseed':\n",
    "            similar_queries = retriever.retrieve_similar_queries(ex['query'],shot_k=5)\n",
    "        elif mode_index == 'randomseed':\n",
    "            sampled_shuffled = random.sample(shuffled, 5)\n",
    "            similar_queries = \"\".join([\"\\nInstruction: \" + ex['query'] + \"\\nFunction: \" + ex['gold'] for ex in sampled_shuffled])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if retrieved_index=='retrieved':\n",
    "            retrieved_api_list = retriever.retrieving(ex['query'], top_k=top_k)\n",
    "            if oracle_index=='corrected':\n",
    "                if ex['gold'] not in retrieved_api_list:\n",
    "                    retrieved_api_list = [ex['gold']] + retrieved_api_list[:-1]\n",
    "                assert ex['gold'] in retrieved_api_list\n",
    "            elif oracle_index=='noncorrected':\n",
    "                pass\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            retrieved_apis = \"\"\n",
    "            for api in retrieved_api_list:\n",
    "                retrieved_apis+=api+\":\"+all_apis_json[api]+\"\\n\"\n",
    "        elif retrieved_index=='nonretrieved':\n",
    "            retrieved_apis = \"\"\n",
    "            for api in all_apis_json:\n",
    "                retrieved_apis+=api+\":\"+all_apis_json[api]+\"\\n\"\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "        #print(prompt.format(query=ex['query'],retrieved_apis=retrieved_apis,similar_queries=similar_queries))\n",
    "        print('--asking--')\n",
    "        p = gpt_interface.query_openai(prompt.format(query=ex['query'],retrieved_apis=retrieved_apis,similar_queries=similar_queries), mode=mode, model=gpt_model, max_tokens=max_tokens)\n",
    "        print('--done--')\n",
    "        p = p.split(',')[0]  # hack for if GPT answers this or that\n",
    "        p = p.split('(')[0]\n",
    "        p = p.split(' or ')[0]\n",
    "        p = p.strip()\n",
    "        ex['pred'] = p\n",
    "        ex['correct'] = c = ex['pred'] == ex['gold']\n",
    "        ex['retrieved_apis'] = retrieved_api_list\n",
    "        correct.append(c)\n",
    "        pbar.set_description('correct: {}'.format(sum(correct)/len(correct)))\n",
    "    with open(os.path.join(dout, '{}.json'.format(title)), 'wt') as f:\n",
    "        json.dump(test, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_name = \"{}-shot-classify\".format(k_shot)\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e8cb9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.6813186813186813: 100%|█████████████████████████████| 182/182 [05:42<00:00,  1.88s/it]'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ed3488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.6593406593406593: 100%|██| 182/182 [01:52<00:00,  1.62it/s]'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 5\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b6f79b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.6703296703296703: 100%|██| 182/182 [13:39<00:00,  4.50s/it]'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "648d8f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7802197802197802: 100%|█| 182/182 [10:15<00:00,  3.3'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "title = f'gpt-4-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d808e5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7912087912087912: 100%|██| 182/182 [10:36<00:00,  3.50s/it]'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 5\n",
    "title = f'gpt-4-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n",
    "#load_errors('5-shot-classify/gpt-4-topk-3.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "afb9707f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7857142857142857: 100%|█| 182/182 [07:02<00:00,  2.32s/it]'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "title = f'gpt-4-topk-{top_k}'\n",
    "run_gpt_new(test, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n",
    "#load_errors('5-shot-classify/gpt-4-topk-3.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77666260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7582417582417582: 100%|█| 182/182 [04:17<00:00,  1.4'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n",
    "#load_errors(f'5-shot-classify/{title}.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e5a1154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7527472527472527: 100%|██| 182/182 [04:18<00:00,  1.42s/it]'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 5\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n",
    "#load_errors(f'5-shot-classify/{title}.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b3c8021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.7582417582417582: 100%|██| 182/182 [02:24<00:00,  1.26it/s]'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "title = f'gpt-3.5-turbo-16k-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-3.5-turbo-16k', prompt, '{}-shot-classify'.format(k_shot), mode,top_k=top_k,title=title)\n",
    "#load_errors(f'5-shot-classify/{title}.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "de3cd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.8516483516483516: 100%|█| 182/182 [06:41<00:00,  2.2'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "title = f'gpt-4-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n",
    "#load_errors('5-shot-classify/gpt-4-topk-3.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7658789",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "title = f'gpt-4-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n",
    "#load_errors('5-shot-classify/gpt-4-topk-3.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a95e8547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct: 0.8516483516483516: 100%|██| 182/182 [07:21<00:00,  2.42s/it]'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "title = f'gpt-4-topk-{top_k}-trainsample'\n",
    "run_gpt_new(val, 'gpt-4', prompt, '{}-shot-classify'.format(k_shot), mode, top_k=top_k,title=title)\n",
    "#load_errors('5-shot-classify/gpt-4-topk-3.json')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2db97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "363788e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 23 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For accuracy without ambiguous pair\n",
    "from collections import defaultdict\n",
    "with open(\"./API_composite.json\", \"r\") as file:\n",
    "    api_composite_data = json.load(file)\n",
    "    \n",
    "api_composite_data = {key:api_composite_data[key] for key in api_composite_data if api_composite_data[key]['api_type']!='class'}\n",
    "\n",
    "# 1: description\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "def find_similar_api_pairs(api_descriptions):\n",
    "    descriptions = list(api_descriptions.values())\n",
    "    api_names = list(api_descriptions.keys())\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(descriptions)\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    similar_pairs = []\n",
    "    for i in range(len(api_names)):\n",
    "        for j in range(i+1, len(api_names)):\n",
    "            if cosine_similarities[i, j] > 0.999:  # threshold can be adjusted\n",
    "                similar_pairs.append((api_names[i], api_names[j]))\n",
    "    return similar_pairs\n",
    "\n",
    "similar_api_pairs = find_similar_api_pairs(all_apis_json)\n",
    "\n",
    "# 2: \n",
    "require_same_depth=False\n",
    "api_list = list(api_composite_data.keys())\n",
    "groups = defaultdict(list)\n",
    "for api in api_list:\n",
    "    parts = api.split('.')\n",
    "    if require_same_depth:\n",
    "        key = (parts[-1], len(parts))\n",
    "    else:\n",
    "        key = parts[-1]\n",
    "    groups[key].append(api)\n",
    "similar_pairs = [group for group in groups.values() if len(group) > 1]# Filter out groups that only contain 1 API (no similar pairs).\n",
    "#for pair in similar_pairs:\n",
    "#    print(pair)\n",
    "\n",
    "list_1 = similar_api_pairs\n",
    "list_2 = similar_pairs\n",
    "pairs_from_list_2 = [(apis[i], apis[j]) for apis in list_2 for i in range(len(apis)) for j in range(i+1, len(apis))]\n",
    "print(len(list_1), len(list_2), len(pairs_from_list_2))\n",
    "merged_pairs = list(set(list_1 + pairs_from_list_2))\n",
    "#merged_pairs = list_2\n",
    "len(merged_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0569d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total</th>\n",
       "      <th>filtered_accuracy</th>\n",
       "      <th>filter_total</th>\n",
       "      <th>top_k</th>\n",
       "      <th>test_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>182</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.878116</td>\n",
       "      <td>361</td>\n",
       "      <td>0.921512</td>\n",
       "      <td>344</td>\n",
       "      <td>3</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>182</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.875346</td>\n",
       "      <td>361</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>346</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>182</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>361</td>\n",
       "      <td>0.936232</td>\n",
       "      <td>345</td>\n",
       "      <td>10</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>182</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.916898</td>\n",
       "      <td>361</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>341</td>\n",
       "      <td>3</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>182</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>170</td>\n",
       "      <td>5</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>361</td>\n",
       "      <td>0.967552</td>\n",
       "      <td>339</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.895604</td>\n",
       "      <td>182</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bak_similar5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.911357</td>\n",
       "      <td>361</td>\n",
       "      <td>0.964809</td>\n",
       "      <td>341</td>\n",
       "      <td>10</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bak_similar5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>182</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>174</td>\n",
       "      <td>-</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bak_similar5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>182</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>175</td>\n",
       "      <td>-</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        task         model_name  accuracy  \\\n",
       "2   bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.884615   \n",
       "5   bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.878116   \n",
       "6   bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.884615   \n",
       "11  bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.875346   \n",
       "4   bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.868132   \n",
       "8   bak_similar5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.894737   \n",
       "7   bak_similar5seed_example/5-shot-classify              gpt-4  0.890110   \n",
       "9   bak_similar5seed_example/5-shot-classify              gpt-4  0.916898   \n",
       "3   bak_similar5seed_example/5-shot-classify              gpt-4  0.879121   \n",
       "13  bak_similar5seed_example/5-shot-classify              gpt-4  0.908587   \n",
       "12  bak_similar5seed_example/5-shot-classify              gpt-4  0.895604   \n",
       "10  bak_similar5seed_example/5-shot-classify              gpt-4  0.911357   \n",
       "1   bak_similar5seed_example/5-shot-generate  gpt-3.5-turbo-16k  0.659341   \n",
       "0   bak_similar5seed_example/5-shot-generate              gpt-4  0.868132   \n",
       "\n",
       "    total  filtered_accuracy  filter_total top_k        test_val  \n",
       "2     182           0.925287           174     3  human annotate  \n",
       "5     361           0.921512           344     3       synthetic  \n",
       "6     182           0.920000           175     5  human annotate  \n",
       "11    361           0.913295           346     5       synthetic  \n",
       "4     182           0.913295           173    10  human annotate  \n",
       "8     361           0.936232           345    10       synthetic  \n",
       "7     182           0.952941           170     3  human annotate  \n",
       "9     361           0.970674           341     3       synthetic  \n",
       "3     182           0.941176           170     5  human annotate  \n",
       "13    361           0.967552           339     5       synthetic  \n",
       "12    182           0.942197           173    10  human annotate  \n",
       "10    361           0.964809           341    10       synthetic  \n",
       "1     182           0.689655           174     -  human annotate  \n",
       "0     182           0.902857           175     -  human annotate  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "results = []\n",
    "\n",
    "def is_pair_in_merged_pairs(gold, pred, merged_pairs):\n",
    "    # Check if the pair (gold, pred) or (pred, gold) exists in merged_pairs\n",
    "    return (gold, pred) in merged_pairs or (pred, gold) in merged_pairs\n",
    "\n",
    "all_apis_from_pairs = set(api for pair in merged_pairs for api in pair)\n",
    "\n",
    "for fname in glob.glob('bak_similar5seed_example/*/*.json'):\n",
    "    with open(fname) as f:\n",
    "        res = json.load(f)\n",
    "    original_correct = [ex['correct'] for ex in res]\n",
    "    original_c = [i for i in original_correct if i]\n",
    "    original_accuracy = sum(original_correct) / len(original_correct) if res else 0\n",
    "    #filtered_res = [item for item in res if item['gold'] not in all_apis_from_pairs]\n",
    "    filtered_res = [item for item in res if not is_pair_in_merged_pairs(item['gold'], item['pred'], merged_pairs)]\n",
    "    \n",
    "    filtered_correct = [ex['correct'] for ex in filtered_res]\n",
    "    filtered_c = [i for i in filtered_correct if i]\n",
    "    filtered_accuracy = sum(filtered_correct) / len(filtered_res) if filtered_res else 0\n",
    "    parent_dir = os.path.dirname(fname)\n",
    "    match = re.search('-topk-(\\d+)', os.path.basename(fname))\n",
    "    top_k = int(match.group(1)) if match else '-'\n",
    "    if os.path.basename(fname).replace('.json', '').startswith('gpt-4'):\n",
    "        model_name = \"gpt-4\"\n",
    "    else:\n",
    "        model_name = \"gpt-3.5-turbo-16k\"\n",
    "    if os.path.basename(fname).replace('.json', '').endswith('trainsample'):\n",
    "        test_val = 'synthetic'\n",
    "    else:\n",
    "        test_val = 'human annotate'\n",
    "    results.append(dict(\n",
    "        task=parent_dir,\n",
    "        model_name=model_name,\n",
    "        accuracy=original_accuracy,\n",
    "        total=len(res),\n",
    "        #total_c = len(original_c),\n",
    "        filtered_accuracy=filtered_accuracy,\n",
    "        #filtered_c = len(filtered_c),\n",
    "        filter_total=len(filtered_res),\n",
    "        top_k=top_k,\n",
    "        test_val=test_val,\n",
    "    ))\n",
    "results = pd.DataFrame(results)\n",
    "results = results.sort_values(by=['task', 'model_name', 'top_k','test_val'])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62e7b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task,model_name,accuracy,total,filtered_accuracy,filter_total,top_k,test_val\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8846153846153846,182,0.9252873563218391,174,3,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8781163434903048,361,0.9215116279069767,344,3,synthetic\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8846153846153846,182,0.92,175,5,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8753462603878116,361,0.9132947976878613,346,5,synthetic\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8681318681318682,182,0.9132947976878613,173,10,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.8947368421052632,361,0.936231884057971,345,10,synthetic\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.8901098901098901,182,0.9529411764705882,170,3,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.9168975069252078,361,0.9706744868035191,341,3,synthetic\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.8791208791208791,182,0.9411764705882353,170,5,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.9085872576177285,361,0.967551622418879,339,5,synthetic\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.8956043956043956,182,0.9421965317919075,173,10,human annotate\n",
      "bak_similar5seed_example/5-shot-classify,gpt-4,0.9113573407202216,361,0.9648093841642229,341,10,synthetic\n",
      "bak_similar5seed_example/5-shot-generate,gpt-3.5-turbo-16k,0.6593406593406593,182,0.6896551724137931,174,-,human annotate\n",
      "bak_similar5seed_example/5-shot-generate,gpt-4,0.8681318681318682,182,0.9028571428571428,175,-,human annotate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_text = results.to_csv(index=False)\n",
    "print(csv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a297fcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total</th>\n",
       "      <th>filtered_accuracy</th>\n",
       "      <th>filter_total</th>\n",
       "      <th>top_k</th>\n",
       "      <th>test_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>182</td>\n",
       "      <td>0.836257</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.775623</td>\n",
       "      <td>361</td>\n",
       "      <td>0.825959</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>182</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>174</td>\n",
       "      <td>5</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.786704</td>\n",
       "      <td>361</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>342</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>182</td>\n",
       "      <td>0.816092</td>\n",
       "      <td>174</td>\n",
       "      <td>10</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.770083</td>\n",
       "      <td>361</td>\n",
       "      <td>0.820059</td>\n",
       "      <td>339</td>\n",
       "      <td>10</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>182</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>173</td>\n",
       "      <td>3</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.867036</td>\n",
       "      <td>361</td>\n",
       "      <td>0.912536</td>\n",
       "      <td>343</td>\n",
       "      <td>3</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>182</td>\n",
       "      <td>0.875740</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.855956</td>\n",
       "      <td>361</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>342</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>182</td>\n",
       "      <td>0.884393</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bak_random5seed_example/5-shot-classify</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.836565</td>\n",
       "      <td>361</td>\n",
       "      <td>0.877907</td>\n",
       "      <td>344</td>\n",
       "      <td>10</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bak_random5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>182</td>\n",
       "      <td>0.222857</td>\n",
       "      <td>175</td>\n",
       "      <td>-</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bak_random5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>0.254848</td>\n",
       "      <td>361</td>\n",
       "      <td>0.268222</td>\n",
       "      <td>343</td>\n",
       "      <td>-</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bak_random5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>182</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>174</td>\n",
       "      <td>-</td>\n",
       "      <td>human annotate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bak_random5seed_example/5-shot-generate</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.396122</td>\n",
       "      <td>361</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>350</td>\n",
       "      <td>-</td>\n",
       "      <td>synthetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       task         model_name  accuracy  \\\n",
       "4   bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.785714   \n",
       "7   bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.775623   \n",
       "8   bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.769231   \n",
       "13  bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.786704   \n",
       "6   bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.780220   \n",
       "10  bak_random5seed_example/5-shot-classify  gpt-3.5-turbo-16k  0.770083   \n",
       "9   bak_random5seed_example/5-shot-classify              gpt-4  0.868132   \n",
       "11  bak_random5seed_example/5-shot-classify              gpt-4  0.867036   \n",
       "5   bak_random5seed_example/5-shot-classify              gpt-4  0.813187   \n",
       "15  bak_random5seed_example/5-shot-classify              gpt-4  0.855956   \n",
       "14  bak_random5seed_example/5-shot-classify              gpt-4  0.840659   \n",
       "12  bak_random5seed_example/5-shot-classify              gpt-4  0.836565   \n",
       "2   bak_random5seed_example/5-shot-generate  gpt-3.5-turbo-16k  0.214286   \n",
       "0   bak_random5seed_example/5-shot-generate  gpt-3.5-turbo-16k  0.254848   \n",
       "1   bak_random5seed_example/5-shot-generate              gpt-4  0.351648   \n",
       "3   bak_random5seed_example/5-shot-generate              gpt-4  0.396122   \n",
       "\n",
       "    total  filtered_accuracy  filter_total top_k        test_val  \n",
       "4     182           0.836257           171     3  human annotate  \n",
       "7     361           0.825959           339     3       synthetic  \n",
       "8     182           0.804598           174     5  human annotate  \n",
       "13    361           0.830409           342     5       synthetic  \n",
       "6     182           0.816092           174    10  human annotate  \n",
       "10    361           0.820059           339    10       synthetic  \n",
       "9     182           0.913295           173     3  human annotate  \n",
       "11    361           0.912536           343     3       synthetic  \n",
       "5     182           0.875740           169     5  human annotate  \n",
       "15    361           0.903509           342     5       synthetic  \n",
       "14    182           0.884393           173    10  human annotate  \n",
       "12    361           0.877907           344    10       synthetic  \n",
       "2     182           0.222857           175     -  human annotate  \n",
       "0     361           0.268222           343     -       synthetic  \n",
       "1     182           0.367816           174     -  human annotate  \n",
       "3     361           0.408571           350     -       synthetic  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample code for the user's requirement\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "results = []\n",
    "\n",
    "def is_pair_in_merged_pairs(gold, pred, merged_pairs):\n",
    "    # Check if the pair (gold, pred) or (pred, gold) exists in merged_pairs\n",
    "    return (gold, pred) in merged_pairs or (pred, gold) in merged_pairs\n",
    "\n",
    "# 将所有API从merged_pairs列表中提取出来\n",
    "all_apis_from_pairs = set(api for pair in merged_pairs for api in pair)\n",
    "\n",
    "for fname in glob.glob('bak_random5seed_example/*/*.json'):\n",
    "    with open(fname) as f:\n",
    "        res = json.load(f)\n",
    "    original_correct = [ex['correct'] for ex in res]\n",
    "    original_c = [i for i in original_correct if i]\n",
    "    original_accuracy = sum(original_correct) / len(original_correct) if res else 0\n",
    "    #filtered_res = [item for item in res if item['gold'] not in all_apis_from_pairs]\n",
    "    filtered_res = [item for item in res if not is_pair_in_merged_pairs(item['gold'], item['pred'], merged_pairs)]\n",
    "    \n",
    "    filtered_correct = [ex['correct'] for ex in filtered_res]\n",
    "    filtered_c = [i for i in filtered_correct if i]\n",
    "    filtered_accuracy = sum(filtered_correct) / len(filtered_res) if filtered_res else 0\n",
    "    parent_dir = os.path.dirname(fname)  # 获取母路径\n",
    "    match = re.search('-topk-(\\d+)', os.path.basename(fname))\n",
    "    top_k = int(match.group(1)) if match else '-'\n",
    "    if os.path.basename(fname).replace('.json', '').startswith('gpt-4'):\n",
    "        model_name = \"gpt-4\"\n",
    "    else:\n",
    "        model_name = \"gpt-3.5-turbo-16k\"\n",
    "    if os.path.basename(fname).replace('.json', '').endswith('trainsample'):\n",
    "        test_val = 'synthetic'\n",
    "    else:\n",
    "        test_val = 'human annotate'\n",
    "    results.append(dict(\n",
    "        task=parent_dir,  # 添加母路径到结果中\n",
    "        model_name=model_name,\n",
    "        accuracy=original_accuracy,\n",
    "        total=len(res),\n",
    "        #total_c = len(original_c),\n",
    "        filtered_accuracy=filtered_accuracy,\n",
    "        #filtered_c = len(filtered_c),\n",
    "        filter_total=len(filtered_res),\n",
    "        top_k=top_k,\n",
    "        test_val=test_val,\n",
    "    ))\n",
    "results = pd.DataFrame(results)\n",
    "results = results.sort_values(by=['task', 'model_name', 'top_k','test_val'])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34ea92ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task,model_name,accuracy,total,filtered_accuracy,filter_total,top_k,test_val\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.7857142857142857,182,0.8362573099415205,171,3,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.775623268698061,361,0.8259587020648967,339,3,synthetic\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.7692307692307693,182,0.8045977011494253,174,5,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.7867036011080333,361,0.8304093567251462,342,5,synthetic\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.7802197802197802,182,0.8160919540229885,174,10,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-3.5-turbo-16k,0.7700831024930748,361,0.8200589970501475,339,10,synthetic\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8681318681318682,182,0.9132947976878613,173,3,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8670360110803325,361,0.9125364431486881,343,3,synthetic\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8131868131868132,182,0.8757396449704142,169,5,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8559556786703602,361,0.9035087719298246,342,5,synthetic\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8406593406593407,182,0.884393063583815,173,10,human annotate\n",
      "bak_random5seed_example/5-shot-classify,gpt-4,0.8365650969529086,361,0.877906976744186,344,10,synthetic\n",
      "bak_random5seed_example/5-shot-generate,gpt-3.5-turbo-16k,0.21428571428571427,182,0.22285714285714286,175,-,human annotate\n",
      "bak_random5seed_example/5-shot-generate,gpt-3.5-turbo-16k,0.2548476454293629,361,0.26822157434402333,343,-,synthetic\n",
      "bak_random5seed_example/5-shot-generate,gpt-4,0.3516483516483517,182,0.367816091954023,174,-,human annotate\n",
      "bak_random5seed_example/5-shot-generate,gpt-4,0.3961218836565097,361,0.4085714285714286,350,-,synthetic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_text = results.to_csv(index=False)\n",
    "print(csv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40c86231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 23)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_1),len(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16f545f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 56)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(api for pair in list_1 for api in pair)), len(set(api for pair in list_2 for api in pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df07107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4984a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
